#!/user/bin/env python3
"""
toprepo merges subrepositories into a common history, similar to git-subtree.

The basic idea is to join all the history from all the subrepositories
in a reproducible way. This means that users can keep a mono repository
locally on their computers but have share commit hashes with everyone else.

Consider the following history and commits:

    Top repo  A---B---C---D-------E---F---G---H
                  |       |       |       |
    Submodule 1---2-------3---4---5---6---7---8

The merged history will look like:

    Mono repo A---B2---C2---D3--E5---F5--G7--H7
                  /          \  /     \  / \\
                 1            D4       F6   G8

... and NOT like:

    BAD REPO  A--B2--C2--D3--D4--E5--F5--G7--H7
                 /\      /         \    /     \\
                1  ------            E6       H8

The algorithm steps are:
* Any history before the submodule is added contains the submodule
  directory only (1).
* Empty edge for the submodule history are removed (2---3).
  Such empty edges would only pollute the graph.
  The mono repo history for the submodule directory would
  show there is no update between the two commits anyway.
* The top repo will keep the "first parent" line (D3---E5).
  D4 might not be buildable and would break
  `git bisect --first-parent`.
* Submodule changes are moved as late as possible before merging (F6).
  The alternative of E6 instead of F6 clutters a graph log view.
  From the top repo view, it is impossible to know if E6 or F6
  is better (buildable) or not.
* Unmerged submodule branches are branched as early as possible.
  It is easier to run `git checkout G8 && git rebase H7` than
  `git checkout H8 && git rebase H7 --onto G7`.
* Unmerged submodule branches are branched from the history of HEAD.
  As commit 7 can be used in multiple top repo branches,
  it is impossible to know which branch commit 8 is aimed for.
  Simply checkout a different monorepo branch and run `toprepo refilter`
  to move unmerged submodule branches around.

Configuration files are stored in the .toprepo directory in the top repo.
If the directory is available in the worktree, that content is used.
Otherwise, it is looked for in `refs/remotes/origin/HEAD` and last
`refs/remotes/origin/toprepo-config`. Only use a .toprepo directory in
your working tree when working on `origin/HEAD` or when testing out a
new configuration.

The file `.toprepo/missing-commits` contains lines with
`<commit hash> SP <raw url> LF` where the raw url is the same as written in
the .gitmodules file. These commits are not expanded when converting to a
mono repo.

The file `.toprepo/config` is on git-config format and is overridden by values
found with `git config --list`. The following configurations are available:

* `toprepo.role`: A named role to use. Defaults to 'default'.
* `toprepo.<role>.repos`: Tells which sub repos to use.
  Multiple values are accumulated.
  Each value starts with '+' or '-' followed by a regexp that should matcha
  whole repository name. `toprepo.default.repos` defaults to `+.*`.
* `toprepo.<repo-name>.url`: Repositories with this specified url in the
  .gitmodules file will be referred to as `repo-name`.
  Multiple values are allowed, but only the first one will be used when
  cloning from upstream.
* `toprepo.<repo-name>.fetchUrl`: Overrides the standard clone and fetch URL.
  Written to `remotes.origin.fetchUrl` after cloning the subrepo.
* `toprepo.<repo-name>.pushUrl`: Overrides the standard push URL.
  Written to `remotes.origin.pushUrl` after cloning the subrepo.
"""
import argparse
from heapq import heappop, heappush
import itertools
import logging
from queue import PriorityQueue
import re
import subprocess
import sys
from collections import defaultdict
from dataclasses import dataclass
from functools import partial
from pathlib import Path, PurePath, PurePosixPath
from typing import (
    DefaultDict,
    Dict,
    List,
    Optional,
    Set,
    Tuple,
    Union,
    overload,
)

try:
    import git_filter_repo
except ImportError:
    print("Please 'pip3 install git-filter-repo'.")
    sys.exit(2)


logger = logging.getLogger(__file__)

RefStr = str
Ref = bytes
TreeHash = bytes
CommitHash = bytes
RepoFilterId = Union[int, CommitHash]


class Repo:
    def __init__(self, repo: Path):
        self.path: Path = repo
        self.git_dir: Path = determine_git_dir(repo)


class TopRepo(Repo):
    is_top = True


@dataclass
class PushRefSpec:
    local_ref: RefStr
    remote_ref: RefStr

    @staticmethod
    def parse(refspec):
        if refspec.count(":") == 0:
            if not refspec.startswith("refs/"):
                refspec = "refs/heads/" + refspec
            refspec = f"{refspec}:{refspec}"
        if refspec.count(":") != 1:
            raise ValueError(f"Multiple ':' found in refspec {refspec}")
        local_ref, remote_ref = refspec.split(":")
        return PushRefSpec(local_ref, remote_ref)


@dataclass
class PushInstruction:
    repo: Repo
    commit_hash: str
    extra_args: List[str]

    def same_but_commit(self, other: "PushInstruction"):
        return self.repo.path == other.repo.path and self.extra_args == other.extra_args


def try_relative_path(path: Path, other: Path = Path.cwd()) -> Path:
    """Returns a relative path, if possible."""
    try:
        return path.relative_to(other)
    except ValueError:
        return path


def determine_git_dir(repo: Path) -> Path:
    git_dir_bytes = git_filter_repo.GitUtils.determine_git_dir(
        str(repo).encode("utf-8")
    )
    return Path(git_dir_bytes.decode("utf-8"))


@dataclass
class GitModuleInfo:
    name: str
    path: PurePosixPath
    branch: Optional[str]
    url: str
    raw_url: str


def get_gitmodules_info(repo: Repo, ref: str) -> List[GitModuleInfo]:
    dot_gitmodules_content = subprocess.check_output(
        repo.path,
        ["show", f"{ref}:.gitmodules"],
    )
    minified_gitmodules = subprocess.check_output(
        repo.path,
        ["config", "--file", "-", "--list"],
        input=dot_gitmodules_content,
    ).decode("utf-8")
    return parse_gitmodules_content(repo.url, minified_gitmodules)


def parse_gitmodules_content(
    parent_url: str, minified_gitmodules_config: str
) -> List[GitModuleInfo]:
    """Parses the output from 'git config --list --file .gitmodules'."""
    lines = minified_gitmodules_config.splitlines(keepends=False)
    config_dicts: DefaultDict[str, Dict[str, str]] = defaultdict(dict)
    submod_prefix = "submodules."
    for line in lines:
        if line.startswith(submod_prefix):
            key, value = line[len(submod_prefix) :].split("=", 1)
            name, field = key.rsplit(".", 2)
            if config_dicts[name].setdefault(field, value) != value:
                raise ValueError(
                    "Conflicting values {line} and {config_dict[name][field]}"
                )

    configs: Dict[PurePosixPath, GitModuleInfo] = {}
    for name, config_dict in config_dicts.items():
        resolved_url = join_submodule_url(parent_url, config_dict["url"])
        submod_info = GitModuleInfo(
            name=name,
            path=PurePosixPath(config_dict["path"]),
            branch=config_dict.get("branch"),
            url=resolved_url,
            raw_url = config_dict["url"],
        )
        if submod_info.path in configs:
            raise ValueError("Duplicated submodule configs for {submod_info.path}")
        configs[submod_info.path] = submod_info

    return list(configs.values())


def join_submodule_url(parent: str, other: str) -> str:
    if other.startswith("./") or other.startswith("../"):
        if "//" in other:
            raise ValueError(f"'//' not allowed in {other!r} (parent={parent!r})")
        scheme, parent = parent.split("://", 1)
        parent = parent.rstrip("/")
        while True:
            if other.startswith("./"):
                other = other[2:]
            elif other.startswith("../"):
                idx = parent.rfind("/")
                if idx == -1:
                    raise ValueError(f"Too many '..' in {other!r} (parent={parent!r})")
                parent = parent[:idx]
                other = other[3:]
            else:
                break
        ret = f"{scheme}://{parent}/{other}"
    else:
        ret = other
    return ret


def resolve_fetch_remote(repo: Repo, remote: str) -> Tuple[Repo, str]:
    if "://" in remote:
        url = remote
    else:
        url = subprocess.check_output(
            ["git", "-C", str(repo.path), "config", f"remote.{remote}.url"],
            text=True,
        ).rstrip("\n")
    return url


def repository_basename(repository: str) -> str:
    # Either if it is an URL or file path, assume a limited set of separators.
    idx = max(repository.rfind(sep) for sep in r"/\:")
    if idx == -1:
        # Use the whole name then.
        idx = 0
    basename = repository[idx:]
    basename = basename.removesuffix(".git")
    return basename


ANNOTATED_TOP_NAME = b"<top>"


def annotate_message(
    message: bytes, name: bytes, orig_commit_hash: CommitHash
) -> bytes:
    missing_trailing_lf = not message.endswith(b"\n")
    ret = message
    if missing_trailing_lf:
        ret += b"\n"
    ret += b"^-- " + name + b" " + orig_commit_hash
    if missing_trailing_lf:
        ret += " (missing newline)"
    ret += "b\n"
    return ret


def try_parse_top_hash_from_message(message: bytes) -> Optional[CommitHash]:
    return try_parse_commit_hash_from_message(message, ANNOTATED_TOP_NAME)


def try_parse_commit_hash_from_message(
    message: bytes, name: str
) -> Optional[CommitHash]:
    name_bytes = name.encode("utf-8")
    hash_annotation_regex = (
        rb"^\^-- %s ([0-9a-f]+)( \(missing newline\))?$" % name_bytes
    )
    matches = list(re.finditer(hash_annotation_regex, message, re.MULTILINE))
    if len(matches) == 0:
        return None
    elif len(matches) > 1:
        raise ValueError(f"Multiple hashes found for {name} in the message {message}")
    else:
        (match,) = matches
    top_commit_hash = match.group(1)
    return top_commit_hash


def try_get_topic_from_message(message: bytes) -> Optional[str]:
    message_str = message.decode("utf-8")
    topic_regex = r"^Topic: (\$+)$"
    matches = list(re.finditer(topic_regex, message_str, re.MULTILINE))
    if len(matches) == 0:
        return None
    if len(matches) > 1:
        raise ValueError(
            "Expected a single footer 'Topic: <topic>' " + "in the message {message}"
        )
    (match,) = matches
    topic = match.group(1)
    return topic


def log_run_git(
    repo: Optional[Path],
    args: List[str],
    check=True,
    dry_run=False,
    log_command=True,
    **kwargs,
) -> Optional[subprocess.CompletedProcess]:
    """Log the git command and run it for the correct repo."""
    full_args: List[str]
    if repo is None:
        full_args = ["git"] + args
    else:
        full_args = ["git", "-C", str(repo)] + args
    cmdline = subprocess.list2cmdline(full_args)
    if dry_run:
        print(f"\rWould run  {cmdline}")
        ret = None
    else:
        if log_command:
            print(f"\rRunning   {cmdline}")
        ret = subprocess.run(full_args, check=check, **kwargs)
    return ret


class Config:
    def __init__(self, toprepo: Repo):
        self.toprepo = toprepo
        self.config_ref = self.static_get_config_ref(toprepo)

    @staticmethod
    def static_get_config_ref(toprepo: Repo) -> Optional[str]:
        # If the user has a config checked out or written for testing, use that.
        if (toprepo.path / ".toprepo").is_dir():
            return None
        # Otherwise, check the git-config.
        result = subprocess.run(
            toprepo.path,
            ["config", "toprepo.config-ref"],
            stdout=subprocess.PIPE,
            text=True,
            check=False,
        )
        if result.returncode == 0:
            return result.stdout.strip()
        elif result.returncode != 1:
            raise subprocess.CalledProcessError(
                result.returncode, result.args, result.stdout, result.stderr
            )
        # Read from specific refs instead.
        config_ref_priority_list = [
            "refs/remotes/origin/toprepo-config",
            "refs/remotes/origin/HEAD",
        ]
        ref_lines = subprocess.check_output(
            ["git", "-C", str(toprepo.path), "show-ref"],
            text=True,
        )
        all_refs = set()
        for line in ref_lines.splitlines(keepends=False):
            commit_hash, ref = line.split(" ", 1)
            all_refs.add(ref)
            _ = commit_hash
        for ref in config_ref_priority_list:
            if ref in all_refs:
                ls_tree_output = subprocess.check_output(
                    ["git", "-C", str(toprepo.path)]
                    + ["ls-tree", ref, "--", ".toprepo"],
                )
                if ls_tree_output != b"":
                    return ref
        # No config found, fall back to disk.
        return None

    def read_file(self, name: str) -> Optional[bytes]:
        return self.static_read_file(self.toprepo, self.config_ref, name)

    @staticmethod
    def static_read_file(
        toprepo: Repo, config_ref: Optional[str], name: str
    ) -> Optional[bytes]:
        ret: Optional[bytes]
        if config_ref is None:
            file_path = toprepo.path / ".toprepo" / name
            if file_path.exists():
                ret = file_path.read_bytes()
            else:
                ret = None
        else:
            if (
                subprocess.check_output(
                    ["git", "-C", str(toprepo.path)]
                    + ["ls-tree", config_ref, "--", ".toprepo/" + name],
                )
                != b""
            ):
                ret = subprocess.check_output(
                    ["git", "-C", str(toprepo.path)] + ["show", f"{config_ref}:{name}"],
                )
            else:
                ret = None
        return ret


class MissingCommits(defaultdict[PurePosixPath, Set[CommitHash]]):
    @overload
    def __init__(self) -> None:
        super().__init__(set)

    def __init__(self, __map: "MissingCommits") -> None:
        super().__init__(set, __map)

    @staticmethod
    def from_file(file_path: Path, missing_file_ok: bool = False) -> "MissingCommits":
        """Read missing commits from file_path.

        Each line in file_path contains "<commit-hash> <submodule-path>".
        Empty lines and lines starting with # are ignored.
        """
        ret: MissingCommits
        if missing_file_ok and not file_path.exists():
            ret = MissingCommits()
        else:
            content_bytes = file_path.read_bytes()
            ret = MissingCommits.from_bytes(content_bytes)
        return ret

    @staticmethod
    def from_bytes(content: bytes) -> "MissingCommits":
        """Read missing commits from bytes.

        Each line in file_path contains "<commit-hash> <submodule-path>".
        Empty lines and lines starting with # are ignored.
        """
        ret = MissingCommits()
        for line in content.splitlines(keepends=False):
            if line == "" or line.startswith(b"#"):
                continue
            commit_hash_bytes, submod_path_bytes = line.split(b" ", 1)
            submod_path = PurePosixPath(submod_path_bytes.decode("utf-8"))
            ret[submod_path] = CommitHash(commit_hash_bytes)
        return ret

    def write(self, file_path: Path):
        """Write missing commits from file_path.

        Each line in file_path contains "<commit-hash> <submodule-path>".
        """
        with file_path.open("wb") as f:
            for key, value in self.items():
                if len(value) == 0:
                    continue
                submod_path_bytes = key.as_posix().encode("utf-8")
                commit_hashes = sorted(value)
                for commit_hash in commit_hashes:
                    f.write(commit_hash + b" " + submod_path_bytes + b"\n")

    def __sub__(self, other: "MissingCommits") -> "MissingCommits":
        return self.difference(other)

    def difference(self, *others: "MissingCommits") -> "MissingCommits":
        other = MissingCommits().union(*others)
        ret = MissingCommits(self)
        for key, values in self.items():
            # Using other.get() to not insert new keys into other.
            values_left = values - other.get(key, set())
            if len(values_left) != 0:
                ret[key] = values_left
        return ret

    def __or__(self, other: "MissingCommits") -> "MissingCommits":
        return self.union(other)

    def union(self, *others: "MissingCommits") -> "MissingCommits":
        ret = MissingCommits()
        for other in [self] + others:
            for key, values in other.items():
                ret[key] |= values
        return ret


class CommitIterator:
    """Sorts commits in history order.

    All children of a given commit will always be returned
    before the commit itself.

    This assumes that the depth attribute has been set in the commits.
    """

    def __init__(self):
        self.queue = []
        """Each entry is written as (-depth, i, commit)
        to get them sorted in order.
        """
        self.commit_ids = set()

        self.order_iter = itertools.count(start=0, step=1)
        """order_iter is used to sort the commits
        in the order they are found.
        """

    def empty(self):
        return not self.queue

    def put(self, commit):
        if commit.id not in self.commit_ids:
            item = (-commit.depth, next(self.order_iter), commit)
            heappush(self.queue, item)

    def peek(self):
        _, _, commit = self.queue[0]
        return commit

    def get(self):
        _, _, commit = heappop(self.queue)
        self.commit_ids.remove(commit)
        return commit


class DevNullWriter:
    def write(self, bytes):
        pass


class DevNullOutputRepoFilter:
    """Defines an output pipe for RepoFilter which discards all data."""

    def __init__(self):
        self._output = DevNullWriter()
        self._import_pipes = None


class SubRepo(Repo):
    is_top = False

    def __init__(self, name: str, repo: Path):
        super().__init__(repo=repo)
        """The name used to refer to this sub repository.

        The name is used in git-config and when storing to disk.
        """
        self.name = name

    @property
    def name_bytes(self) -> bytes:
        return self.name.encode("utf-8")


class CommitMap:
    def __init__(self):
        self.id_to_commit: Dict[int, git_filter_repo.Commit] = {}
        """Maps from a commit hash to the original submodule commit."""

        self.hash_to_commit: Dict[CommitHash, git_filter_repo.Commit] = {}

    @staticmethod
    def collect_tree_hashes(repo: Repo) -> Dict[CommitHash, TreeHash]:
        """Get all commit hashes and map to tree hashes in a repo."""
        result = subprocess.check_output(
            ["git", "-C", str(repo.path)] + ["log", "--format=%H %T", "--all", "--"]
        )
        commit_to_tree: Dict[CommitHash, TreeHash] = {}
        for line in result.stdout.splitlines(keepends=False):
            commit_hash, tree_hash = line.split(b" ", 1)
            commit_to_tree[commit_hash] = tree_hash
        return commit_to_tree

    def collect_commits(self, repo: Repo):
        """Loads metadata about all commits."""
        commit_to_tree = self.collect_tree_hashes(repo)

        args = git_filter_repo.FilterOptions.parse_args(
            ["--partial", "--refs", "dummy"]
            + ["--source", str(repo.path)]
            # --target must be the same as --source but is overridden later.
            + ["--target", str(repo.path)]
        )
        args.refs = ["--all"]
        filter = git_filter_repo.RepoFilter(
            args,
            commit_callback=partial(
                self._collect_commit_callback, commit_to_tree
            ),
        )
        filter.set_output(DevNullOutputRepoFilter())
        filter.run()

    def _collect_commit_callback(self, commit_to_tree, commit, metadata):
        commit.depth = 1 + max(
            (
                self.id_to_commit[parent_id].depth
                for parent_id in commit.parents
                if isinstance(parent_id, int)
            ),
            default=0,
        )
        self.id_to_commit[commit.id] = commit
        self.hash_to_commit[commit.original_id] = commit
        commit.tree_hash = commit_to_tree[commit.original_id]


@dataclass
class Remote:
    url: str
    name: str


@dataclass(frozen=True)
class BumpInfo:
    subrepo_commit: git_filter_repo.Commit
    """The original commit from the sub repo."""

    mono_commit: git_filter_repo.Commit
    """The commit in the mono repo that updates the sub directory content,
    i.e. the translated top repo commit which did contain a bump of
    the sub repo compared to any parent.

    This variable is used to fast track searches through the first-parent
    chain.
    """


class SubmoduleFilter:
    def __init__(self, repo: Repo):
        self.submodule_configs: Optional[Dict[bytes, GitModuleInfo]] = None
        """Set to None to reload from .gitmodules when needed."""

        self.repo = repo

    def reset_callback(self):
        self.submodule_configs = None

    def commit_callback(
        self, commit: git_filter_repo.Commit
    ) -> List[Tuple[git_filter_repo.FileChange, Optional[GitModuleInfo]]]:
        for file_change in commit.file_changes:
            if file_change.filename == b".gitmodules":
                self.submodule_configs = None

        ret: List[Tuple[git_filter_repo.FileChange, Optional[GitModuleInfo]]] = []
        for file_change in commit.file_changes:
            submodule_mode = b"160000"
            if file_change.mode == submodule_mode:
                if file_change.type == b"D":
                    ret.append((file_change, None))
                else:
                    if self.submodule_configs is None:
                        # .gitmodules has changed, reload.
                        ref = commit.original_id.decode("utf-8")
                        self.submodule_configs = {
                            config.path.as_posix.encode("utf-8"): config
                            for config in get_gitmodules_info(self.repo, ref)
                        }
                    submod_config = self.submodule_configs.get(file_change.filename)
                    if submod_config is not None:
                        ret.append((file_change, submod_config))
                    else:
                        print(
                            "WARNING: Unknown submodule "
                            + file_change.decode("utf-8")
                            + " at commit "
                            + commit.original_id.decode("utf-8")
                        )
        return ret


class ReferencedSubmodCommitsCollector:
    def __init__(self, repo: Repo):
        self.referenced_commits: Dict[str, Set[CommitHash]]
        """Mapping from submodule url to commit hashes."""

        self.submodule_filter = SubmoduleFilter(repo)

    def reset_callback(self, reset: git_filter_repo.Reset):
        self.submodule_filter.reset_callback()

    def commit_callback(self, commit: git_filter_repo.Commit, metadata):
        submods = self.submodule_filter.commit_callback(commit)
        for file_change, submodule_config in submods:
            if submodule_config is not None:
                url = submodule_config.url
                self.referenced_commits[url].add(file_change.blob_id)

    @staticmethod
    def collect(repo: Repo) -> Dict[str, Set[CommitHash]]:
        """Iterates through a repository and collects submodule commits.

        Returns:
            A mapping from submodule url to commit hashes.
        """
        collector = ReferencedSubmodCommitsCollector()

        args = git_filter_repo.FilteringOptions.parse_args(
            ["--partial", "--refs", "dummy"]
            + ["--source", str(repo.path)]
            # --target must be the same as --source but is overridden later.
            + ["--target", str(repo.path)]
        )
        args.refs = ["--all"]
        filter = git_filter_repo.RepoFilter(
            args,
            commit_callback=collector.commit_callback,
            reset_callback=collector.reset_callback,
        )
        filter.set_output(DevNullOutputRepoFilter())
        filter.run()

        return collector.referenced_commits


class RepoMerger:
    def __init__(self, toprepo: TopRepo):
        self.toprepo = toprepo
        self.config = Config(toprepo)

        self.commit_map = CommitMap()
        self.submodule_filter = SubmoduleFilter(toprepo)

        missing_commits_bytes = self.config.read_file("missing-commits")
        self.missing_commits = MissingCommits.from_bytes(missing_commits_bytes)

        self.fetched_repos: List[Repo] = []
        self.converted_ids: Dict[RepoFilterId, RepoFilterId] = {}

    def fetch_repo(self, repo: SubRepo, ref_arg: Optional[str] = None):
        """Make all the repo content available in the toprepo.

        All the blobs and trees need to be accessible within the toprepo.
        This filtering will copy all the data over."""
        # TODO: Skip already copied stuff from previous runs.
        # TODO: This needs storing all the references.
        if repo in self.fetched_repos:
            raise RuntimeError(f"Repo {repo} has already been fetched")

        # First fetch into the individual repository.
        ref_args = [ref_arg] if ref_arg is not None else []
        log_run_git(
            repo.path,
            [
                "fetch",
                "--quiet",
                "--prune",
                "--prune-tags",
                "--tags",
                "origin",
            ]
            + ref_args,
        )
        # Then move the blobs over to the monorepo.
        if repo.is_top:
            repo_namespace = "top"
        else:
            repo_namespace = f"sub/{repo.name}"
        log_run_git(
            self.toprepo.path,
            [
                "fetch",
                "--quiet",
                "--prune",
                str(repo.path),
                f"+refs/*:refs/{repo_namespace}/",
            ],
        )

    def filter_toprepo(self, allow_fetching: bool):
        """Perform the toprepo filtering.

        Submodules will be fetched and filtered on demand.
        """
        submod_commits = ReferencedSubmodCommitsCollector.collect(self.toprepo)
        subrepos = []
        for url in submod_commits.keys():
            if url not in self.config:
                print("ERROR: Subrepo {url} not configured in .toprepo config.")
                return False
            subrepo_config = self.config.subrepos[url]
            if subrepo_config.enabled:
                subrepo_path = self.toprepo.git_dir / "toprepo/sub" / subrepo_config.name
                subrepo = SubRepo(subrepo_path)
                self.commit_map.collect_commits(subrepo)
        self.commit_map.collect_commits(self.toprepo)

        # Check that all wanted commits exists.
        # It doesn't matter in which repo they were found in,
        # but the url tells us where to try to fetch from.
        if allow_fetching:
            for url, referenced_commits in submod_commits.keys():
                commits_to_fetch = referenced_commits - set(self.commit_map.hash_to_commit.keys()) - self.missing_commits[url]
                if len(commits_to_fetch) != 0:
                    self.fetch_repo(subrepo)
        commits_are_still_missing = False
        for url, referenced_commits in submod_commits.keys():
            commits_to_fetch = referenced_commits - set(self.commit_map.hash_to_commit.keys()) - self.missing_commits[url]
            for commit_hash in sorted(commits_to_fetch):
                if not commits_are_still_missing:
                    commits_are_still_missing = True
                    print("ERROR: Some referenced commits could not be found")
                    print("Either push the following commits or "
                          "add them to .toprepo/missing-commits.")
                print(commit_hash.decode("utf-8") + " " + url)
        if commits_are_still_missing:
            return False

        # self.fetch_repo(subrepo)
        # subrepo.collect_subrepo_commits()
        # TODO: Load already filtered .git/toprepo/top/toprepo-mapping
        # TODO: Proper filter toprepo.
        # TODO: Remove old refs.
        pass

    def expand_toprepo(self, top_refs: List[str] = ["--all"]):
        args = git_filter_repo.FilteringOptions.parse_args(
            ["--partial", "--refs", "dummy"]
            + ["--source", str(toprepo.path)]
            + ["--target", str(monorepo.path)]
        )
        args.refs = top_refs
        filter = None
        filter = git_filter_repo.RepoFilter(
            args,
            reset_callback=self._expand_toprepo_reset_callback,
            commit_callback=partial(self._expand_toprepo_commit_callback, filter),
        )
        filter.run()

    def _expand_toprepo_reset_callback(self, reset: git_filter_repo.Reset):
        self.submodule_filter.reset_callback()

    def _expand_toprepo_commit_callback(
        self,
        repo_filter: git_filter_repo.RepoFilter,
        mono_commit: git_filter_repo.Commit,
        metadata,
    ):
        self.mono_id_to_commit[mono_commit.id] = mono_commit
        first_parent_id = mono_commit.first_parent()
        if first_parent_id is not None:
            first_parent = self.mono_id_to_commit[first_parent_id]
            mono_commit.bumps = dict(first_parent.bumps)  # Copy
        else:
            mono_commit.bumps = {}  # Dict[bytes, BumpInfo]

        commit_message_parts = [
            annotate_message(
                mono_commit.message, ANNOTATED_TOP_NAME, mono_commit.original_id
            )
        ]

        submods = self.submodule_filter.commit_callback(mono_commit)
        for file_change, submodule_config in submods:
            if file_change.type == b"M":
                subrepo = self.get_subrepo(submodule_config.url)
                # TODO: Get submodule info from submod_path?
                commit_message_parts += self._expand_submod_in_commit_callback(
                    repo_filter,
                    subrepo,
                    mono_commit,
                    file_change,
                )
            elif file_change.type == b"D":
                mono_commit.bumps.pop(file_change.filename)
            elif file_change.type == b"R":
                raise NotImplementedError("Submodule renames are not implements.")
            else:
                assert False, f"Unknown file change type {file_change.type}"

        # Check if any subrepo was bumped here.
        for subdir, bump_info in mono_commit.bumps.items():
            for pid in mono_commit.parents:
                parent_bump = self.mono_id_to_commit[pid].bumps.get(subdir)
                if (
                    parent_bump is None
                    or parent_bump.subrepo_commit != bump_info.subrepo_commit
                ):
                    # subdir was bumped.
                    mono_commit.bumps[subdir] = BumpInfo(
                        subrepo_commit=bump_info.subrepo_commit,
                        mono_commit=mono_commit,
                    )
                    break

        mono_commit.message = join_annotated_commit_messages(commit_message_parts)

    def _expand_submod_in_commit_callback(
        self,
        repo_filter: git_filter_repo.RepoFilter,
        subrepo: SubRepo,
        mono_commit: git_filter_repo.Commit,
        file_change: git_filter_repo.FileChange,
    ) -> List[bytes]:
        """Injects the submodule commit history up to the commit referenced by file_change.

        Returns:
            A list of annotated commit messages to attach to mono_commit.
        """
        commit_message_parts = []
        submod_hash: CommitHash = file_change.blob_id
        submod_commit = subrepo.hash_to_commit.get(submod_hash)
        if submod_commit is not None:
            # Swap commit to tree.
            tree_mode = b"040000"
            file_change.mode = tree_mode
            file_change.blob_id = submod_commit.tree_hash
            commit_message_parts.append(
                annotate_message(
                    submod_commit.message, file_change.filename, submod_hash
                )
            )
            # Recreate the history of the submodule commit graph.
            new_mono_parent_ids = self._inject_subrepo(
                repo_filter, mono_commit, subrepo, submod_commit
            )
            for pid in new_mono_parent_ids:
                if pid not in mono_commit.parents:
                    mono_commit.parents.append(pid)
        else:
            # Missing commit, leave as a submodule reference.
            pass

        mono_commit.bumps[file_change.path] = BumpInfo(
            subrepo_commit=submod_commit,
            mono_commit=mono_commit,
        )
        return commit_message_parts

    def _inject_subrepo(
        self,
        repo_filter: git_filter_repo.RepoFilter,
        target_mono_commit: git_filter_repo.Commit,
        subdir: bytes,
        subrepo: SubRepo,
        subrepo_commit_to_insert: git_filter_repo.Commit,
    ) -> List[int]:
        """Injects the history of subrepo_commit_to_insert into the monorepo.

        subrepo_commit_to_insert refers to a commit in a sub repo that a top repo
        commit refers to. That content is merged into the converted top commit.
        When a sub repo is bumped, there might be a long history in the
        sub repo that also needs to be merged. All those commits are resolved
        and inserted here.
        """
        counter = itertools.count(start=0, step=1)

        def bump_generator(max_subrepo_commit_depth: int):
            mono_queue_ids: Set[int] = set()
            mono_queue = PriorityQueue()
            mono_queue.put((0, next(counter), target_mono_commit))

            while not mono_queue.empty():
                _, _, mono_commit = mono_queue.get()
                bump = mono_commit.bumps.get(subdir)
                if bump is not None:
                    if bump.subrepo_commit.depth > max_subrepo_commit_depth:
                        # The subrepo pointer has reversed in the history.
                        # Stop tracing that branch, merge from the subrepo
                        # source if needed instead.
                        continue
                    max_subrepo_commit_depth = bump.subrepo_commit.depth
                    yield bump
                    # Dig deeper.
                    for pid in bump.mono_commit.parent_id:
                        # Prioritize by subrepo depth, not monorepo depth.
                        # Otherwise, we don't know when we have looked far
                        # enough as the depths are not correlated.
                        if pid not in mono_queue_ids:
                            mono_queue_ids.add(pid)
                            mono_queue.put(
                                (
                                    -bump.subrepo_commit.depth,
                                    next(counter),
                                    self.mono_id_to_commit[pid],
                                )
                            )

        bump_iterator = bump_generator(subrepo_commit_to_insert.depth - 1)

        commits_to_convert: List[git_filter_repo.Commit] = []
        subrepo_id_to_converted_id: Dict[int, int] = {}

        sub_queue_ids: Set[int] = set()
        sub_queue = PriorityQueue()
        sub_queue.put(
            (-subrepo_commit_to_insert.depth, next(counter), subrepo_commit_to_insert)
        )
        # Get the loop going, initialize bump.
        bump = BumpInfo(subrepo_commit=subrepo_commit, mono_commit=None)
        while not sub_queue.empty():
            _, _, subrepo_commit = sub_queue.get()

            while bump.subrepo_commit.depth >= subrepo_commit.depth:
                # Some paths in the monorepo history has found a subrepo
                # commit that is close to a root than subrepo_commit.
                # Don't search further now, because the assumption is that
                # getting closer to a monorepo root should mean closer
                # to the subrepo root.
                try:
                    bump = next(bump_iterator)
                except StopIteration:
                    break
                # Do not override the bump_commit that was found previously,
                # as this loop is going back in the history and
                # the map should point to (one of the) newest commits.
                # There might be multiple valid solutions,
                # so just use the first one found.
                subrepo_id_to_converted_id.setdefault(
                    bump.subrepo_commit.id, bump.mono_commit.id
                )

            if subrepo_commit.id not in subrepo_id_to_converted_id:
                # No good already sub->mono converted candidate was found
                # in the monorepo.
                commits_to_convert.append(subrepo_commit)
                for pid in subrepo_commit.parents:
                    if pid not in sub_queue_ids:
                        sub_queue_ids.add(pid)
                        subrepo_parent = subrepo.id_to_commit[pid]
                        sub_queue.put(
                            (-subrepo_parent.depth, next(counter), subrepo_parent)
                        )

        # Skip subrepo_commit_to_insert itself,
        # git-filter-repo is inserting it for us when returning.
        assert commits_to_convert[0] == subrepo_commit_to_insert
        for subrepo_commit in reversed(commits_to_convert[1:]):
            new_commit = self._create_mono_commit_from_subrepo_commit(
                subdir, subrepo, subrepo_commit
            )
            repo_filter.insert(new_commit, direct_insertion=True)
            # Record subrepo trace info.
            first_parent_id = new_commit.first_parent()
            if first_parent_id is None:
                new_commit.bumps = {}
            else:
                first_parent = self.mono_id_to_commit[first_parent_id]
                new_commit.bumps = dict(first_parent.bumps)  # Copy
            new_commit.bumps[subdir] = BumpInfo(
                subrepo_commit=subrepo_commit,
                mono_commit=new_commit,
            )

        ret = [
            subrepo_id_to_converted_id[parent_id]
            for parent_id in subrepo_commit_to_insert.parents
        ]
        return ret


def main_init(args):
    if args.directory is not None:
        subdir = args.directory
    else:
        subdir = repository_basename(args.repository)
    toprepo_dir: Path = args.cwd / subdir
    if toprepo_dir.exists():
        print(f"ERROR: {toprepo_dir} already exists")
        return 1
    if not toprepo_dir.parent.exists():
        print(f"ERROR: The directory {toprepo_dir.parent} is missing")
        return 1
    toprepo_dir.mkdir()
    log_run_git(toprepo_dir, ["init", "--quiet"])
    toprepo = TopRepo(toprepo_dir)
    log_run_git(
        toprepo.path,
        ["clone", "--bare", args.repository, toprepo.git_dir / "toprepo/top"],
    )

    repo_merger = RepoMerger(toprepo)
    if not repo_merger.filter_toprepo(fetch_subrepos_on_demand=True):
        return 1
    print(f"Initialization of {toprepo.path} succeeded!")
    print("Run 'toprepo fetch && git checkout origin/main' to start.")
    return 0


def main_refilter(args):
    toprepo = TopRepo(args.cwd)
    repo_merger = RepoMerger(toprepo)
    if args.from_scratch:
        # TODO: Remove all refs from toprepo.
        # TODO: Clear the caches.
        # repo_merger.clear_refs()
        # repo_merger.clear_caches()
        raise NotImplementedError("refilter from scratch")
    if not repo_merger.filter_toprepo(fetch_subrepos_on_demand=False):
        return 1
    return 0


def main_fetch(args):
    toprepo = TopRepo(args.cwd)
    orig_repo, remote = resolve_fetch_remote(toprepo, args.remote)
    if orig_repo is None:
        return 1
    ref_args: List[str]
    if args.ref is not None:
        # Fetch ref to refs/top-fetch-head instead of FETCH_HEAD.
        # Then there is no need for extra args to git-filter-repo to pick up FETCH_HEAD.
        ref_args = [f"{args.ref}:refs/top-fetch-head"]
    else:
        # Fetch according to the git config.
        ref_args = []

    repo_merger = RepoMerger(toprepo)
    log_run_git(
        orig_repo.path,
        ["fetch", "--prune", "--prune-tags", "--tags", remote] + ref_args,
    )

    if args.do_filter:
        if not repo_merger.filter_toprepo(fetch_subrepos_on_demand=True):
            return 1
        if args.ref is not None:
            # Update FETCH_HEAD.
            if orig_repo.is_top:
                fetch_head_ref = "refs/top-fetch-head"
            else:
                fetch_head_ref = "refs/sub/{orig_repo.name}/top-fetch-head"
            log_run_git(toprepo.path, ["update-ref", "FETCH_HEAD", fetch_head_ref])
    else:
        print("Skipping monorepo filtering")
    return 0


def main_push(args):

    raise NotImplementedError(args)


def _parse_arguments(argv):
    # Support pasting normal git commands to this script.
    # For example
    #   toprepo git fetch <server> ref
    # should map to
    #   toprepo fetch <server> ref
    if len(argv) > 2 and argv[1] == "git":
        argv.pop(1)

    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawTextHelpFormatter,
        prog=Path(argv[0]).name,
    )
    parser.add_argument(
        "-C",
        dest="cwd",
        type=Path,
        default=Path.cwd(),
        help="Working directory, defaults to '.'.",
    )
    parser.set_defaults(func=None)
    subparsers = parser.add_subparsers()

    init_parser = subparsers.add_parser(
        "init",
        description="""\
            Clones a top repository and initializes a mono repository in the current directory.
        """,
    )
    init_parser.set_defaults(func=main_init)
    init_parser.add_argument(
        "repository",
        type=str,
        nargs=1,
        help="""\
            The URL to the top repository to clone,
            i.e. the repository containing the submodules.""",
    )
    init_parser.add_argument(
        "directory",
        type=PurePath,
        nargs="?",
        help="""\
            Where to initialize the repository.
            Defaults to the base name of the repository.""",
    )

    refilter_parser = subparsers.add_parser(
        "refilter",
        description="Performes a refiltering of the monorepo.",
    )
    refilter_parser.set_defaults(func=main_refilter)
    refilter_parser.add_argument(
        "--from-scratch",
        dest="from_scratch",
        action="store_true",
        help="""\
            Removes previous filtering results and starts over again.

            This option will remove all refs/* apart from refs/heads/*
            and clear the caches about what commits have been filtered.
            Performing this refiltering might generate new commit hashes
            in the git history, if the algorithm has changed or
            the submodule commit ignore list has been updated.""",
    )

    fetch_parser = subparsers.add_parser(
        "fetch",
        description="""\
            Fetches the top repository and resolves all refs into the monorepo.
            If any referenced submodule commit is missing,
            the submodule will also be fetched.

            FETCH_HEAD will be updated if a single ref is is specified.
            """,
    )
    fetch_parser.set_defaults(func=main_fetch)
    fetch_parser.add_argument(
        "--skip-filter",
        action="store_false",
        dest="do_filter",
        help="Fetch from the remote but skip monorepo filtering.",
    )
    fetch_parser.add_argument(
        "remote",
        type=str,
        nargs="?",
        help="""\
            The URL or a submodule path to fetch from.
            Will fetch from the top repository remote
            if 'origin', '.' or '' is specified.""",
    )
    fetch_parser.add_argument(
        "ref",
        type=str,
        nargs="?",
        help="""\
            The 'refspec' to be fetched from the specified remote.
            If a single ref is specified,
            FETCH_HEAD will be updated accordingly.""",
    )

    push_parser = subparsers.add_parser(
        "push",
        description="""\
            Splits the monorepo into commits to push and pushes them.

            'refs/heads/push' will be updated in the top repository and
            each affected submodule.""",
    )
    push_parser.set_defaults(func=main_push)
    push_parser.add_argument(
        "--dry-run",
        "-n",
        action="store_true",
        help="""\
            Split the monorepo commits and write the git-push commands
            that should have been executed.

            Use this option to push to manually push a different repository
            than the default configured 'origin'.""",
    )
    push_parser.add_argument(
        "remote",
        type=str,
        nargs="?",
        choices=["origin"],
        help="""\
            Unused placeholder in case the user writes 'origin'
            on the command line, like with git-push.""",
    )
    push_parser.add_argument(
        "local_and_remote_ref",
        metavar="local-ref:remote-ref",
        type=PushRefSpec.parse,
        nargs=1,
        help="""\
            The refspec describing what to push, just like git-push.

            If a single branch name is specified, it is translated into
            'refs/heads/<branch>:refs/heads/<branch>'.""",
        # TODO: Follow upstream settings in .git/config for the monorepo.
    )

    args = parser.parse_args(argv[1:])
    if args.func is None:
        parser.print_help()
        parser.exit(status=2)
    args.cwd = try_relative_path(args.cwd)
    return args


def main(argv):
    args = _parse_arguments(argv)

    mono_repo = Path(
        subprocess.chec_output(
            ["git", "-C", str(args.cwd), "rev-parse", "--show-toplevel"],
            text=True,
        ).rstrip("\n")
    )
    # Make relative for shorter error messages.
    try:
        mono_repo = mono_repo.relative_to(Path.cwd())
    except ValueError:
        pass
    try:
        returncode = args.func(args=args, mono_repo=mono_repo)
    except subprocess.CalledProcessError as err:
        cmdline = subprocess.list2cmdline(err.args)
        print(f"\rFailed to call  {cmdline}")
        raise
    assert isinstance(returncode, int), returncode
    return returncode


if __name__ == "__main__":
    sys.exit(main(sys.argv))
